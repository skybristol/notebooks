{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extracted PDF Annotation via Zotero.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNFgsYfm/J8DEpqH1uEFyyB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skybristol/notebooks/blob/master/Extracted_PDF_Annotation_via_Zotero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtzwSnLRFKAJ"
      },
      "source": [
        "I'm experimenting here with a process to turn annotations created within PDF files stored as part of a Zotero library into metadata contents and structured annotations for the bibliographic record. This is essentially for cases where there is not good citation metadata already in existence somewhere on the web (e.g., for certain types of government reports) and we need to extract that content from within PDFs. It's also for cases where built-in structured PDF metadata is no good, which is the case for anything other than professionally built PDFs (e.g., just exporting a PDF from your word processor does not build a good PDF). This technique also holds promise for setting up training data for building various kinds of entity recognition models to auto-extract particular concepts from full texts processed with NLP.\n",
        "\n",
        "I used a combination of the ZotFile and MDNotes for Zotero plugins, inspired by [this video](https://www.youtube.com/watch?v=_Fjhad-Z61o&t=1251s). In Zotero, the process includes storing the PDF file as an attachment so that Zotero is \"managing\" it, annotating the file using some type of PDF markup tool (I used Preview on Mac), running the ZotFile tool to extract annotations from the PDF (creating a note in Zotero), and then using MDNotes to export the ZotFile extraction to a markdown file. I uploaded that raw MD file here for this experiment.\n",
        "\n",
        "For annotation, I used a combination of highlighting particular text and then tagging that text with a keyword corresponding to a target part of the citation metadata I'm trying to identify (e.g., title, authors, etc.). I should then be able to pull these two pieces out of the generated markdown into a data structure that I can feed back into the corresponding record via the Zotero API.\n",
        "\n",
        "For the Python part of this, I used a combination of the python-markdown package, which converts the markdown to HTML and then BeautifulSoup to work with the HTML. I experimented with the py2md package, but got a little lost in the navigation they set up.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tah2x2bj9UWH"
      },
      "source": [
        "import markdown\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vULdcZcWA-5V",
        "outputId": "88661272-b889-402f-a765-fbc57eb7b805"
      },
      "source": [
        "annotations_html = markdown.markdown(open(\"/content/UnknownTitle - Extracted Annotations (862021, 41048 AM).md\", \"r\").read())\n",
        "annotations_soup = BeautifulSoup(annotations_html, 'html.parser')\n",
        "\n",
        "raw_notes = annotations_soup.find_all(\"blockquote\")\n",
        "raw_props = annotations_soup.find_all(\"em\")\n",
        "zotero_group_id = annotations_soup.find(\"a\")[\"href\"].split(\"/\")[4]\n",
        "zotero_file_id = annotations_soup.find(\"a\")[\"href\"].split(\"/\")[6].split(\"?\")[0]\n",
        "\n",
        "d_annotations = list()\n",
        "for index,note in enumerate(raw_notes):\n",
        "  d_annotations.append({\n",
        "      \"zotero_group_id\": zotero_group_id,\n",
        "      \"zotero_file_id\": zotero_file_id,\n",
        "      \"text\": note.find(\"p\").text.split('\" (')[0].replace('\"', \"\"),\n",
        "      \"property\": raw_props[index].text.split(\" (\")[0]\n",
        "  })\n",
        "\n",
        "d_annotations"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'property': 'institution',\n",
              "  'text': 'BULLFROG GOLD CORP.',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'},\n",
              " {'property': 'title',\n",
              "  'text': 'NI 43-101 Technical Report Mineral Resource Estimate Bullfrog Gold Project Nye County, Nevada',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'},\n",
              " {'property': 'date',\n",
              "  'text': 'August 9, 2017',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'},\n",
              " {'property': 'author',\n",
              "  'text': 'Rex Bryan',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'},\n",
              " {'property': 'project',\n",
              "  'text': 'Bullfrog Gold Project',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'},\n",
              " {'property': 'place',\n",
              "  'text': 'Bullfrog Mining District',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'},\n",
              " {'property': 'place',\n",
              "  'text': 'Bullfrog Hills',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'},\n",
              " {'property': 'place',\n",
              "  'text': 'Nye County',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'},\n",
              " {'property': 'place',\n",
              "  'text': 'Nevada',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'},\n",
              " {'property': 'commodity',\n",
              "  'text': 'gold',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'},\n",
              " {'property': 'commodity',\n",
              "  'text': 'silver',\n",
              "  'zotero_file_id': 'K5C5CT2F',\n",
              "  'zotero_group_id': '4373054'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJFRZHCoH4oE"
      },
      "source": [
        "What I did above so far is a reasonable start, but there are a few issues.\n",
        "\n",
        "* This is pretty brittle at this point and requires a very specific convention to be followed in annotating a PDF text. This would need to be made a bit more robust in terms of dealing with text strings and different things people might do in free and open annotations. However, some type of conventions would need to be established and followed in terms of highlighting a chunk of text and then marking up its particular significance. If we want to simply pick out the major elements of reasonably complete citation metadata, then something like I tried here should work well enough.\n",
        "* The annotations as extracted by ZotFile and translated to markdown include links intended to take a user working on a local system right to the particular part of a PDF file referenced in the annotation. This is cool in practical use, but it also includes two necessary identifiers that I pulled into the structure above for the group library and the PDF file that was annotated. These do correspond to the identifiers used online for the synced library and contents, which should presumably allow me to identify where the annotations came from in terms of the Zotero library catalog item itself. I will have to lookup the file identifer and figure out what item it belongs to in order to get that identifier to inject the annotated/extracted metadata.\n",
        "* The operational part of this is what gets a little clunky as it relates to working within a shared group library context or fully automating a processing workflow. The actual entity being operated on here is exported to a markdown file from within a particular client instance of Zotero working on a shared library item. There's a batch export process which could be used, but the markdown files have to be sent somewhere for processing. We can put those files in as additional attachments on the Zotero item and sync them, but the behavior of the MDNotes plugin is to dialog that process. I may be able to work on using the actual notes created by Zotfile, which I think I can get at through the API and bypass the markdown part of things - I just need to work out how to parse the notes in much the same way.\n",
        "\n",
        "My takeaway so far is that it's actually really nice and fast to simply open up a PDF file and start marking it up. Theoretically, this could be done on a whole batch of PDFs totally separate from Zotero, bulk import those to Zotero, run the ZotFile extraction on the annotations, and then generate properly documented items. For the types of files this applies to, Zotero is not going to recognize that they should be \"report\" type items, so that part of things would need to be handled through the API. As noted, the real point here is to train an AI to do this work, at least within some contextual boundaries. But even if it was a person sitting down doing this work, it should be much faster to open a PDF, mark it up following a particular convention to identify the important bits, and then have a system take over to parse and catalog the files."
      ]
    }
  ]
}